{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OfxkwWeenIpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced5e01c-5184-4ba4-df5c-7e7ed98810b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pylangacq\n",
            "  Downloading pylangacq-0.18.0-py3-none-any.whl (65 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pylangacq) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from pylangacq) (2.31.0)\n",
            "Requirement already satisfied: tabulate[widechars]>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from pylangacq) (0.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.0.0->pylangacq) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->pylangacq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->pylangacq) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->pylangacq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->pylangacq) (2023.11.17)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.2.12)\n",
            "Installing collected packages: pylangacq\n",
            "Successfully installed pylangacq-0.18.0\n",
            "Collecting pronouncing\n",
            "  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmudict>=0.4.0 (from pronouncing)\n",
            "  Downloading cmudict-1.0.15-py3-none-any.whl (939 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<7.0,>=5.1 in /usr/local/lib/python3.10/dist-packages (from cmudict>=0.4.0->pronouncing) (6.8.0)\n",
            "Collecting importlib-resources<6.0.0,>=5.10.1 (from cmudict>=0.4.0->pronouncing)\n",
            "  Downloading importlib_resources-5.13.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=5.1->cmudict>=0.4.0->pronouncing) (3.17.0)\n",
            "Building wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6234 sha256=5c4275777e741b557cd69e5a67561c959a51c22a07449afd2899b8d3da1679d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/f6/1d/599c67da1fa48c086d8c49e8fc6bd5f05bc9fa66fb04bed5db\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: importlib-resources, cmudict, pronouncing\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 6.1.1\n",
            "    Uninstalling importlib-resources-6.1.1:\n",
            "      Successfully uninstalled importlib-resources-6.1.1\n",
            "Successfully installed cmudict-1.0.15 importlib-resources-5.13.0 pronouncing-0.2.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Installing collected packages: cloudpathlib, weasel, spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.7.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpathlib-0.16.0 spacy-3.7.2 weasel-0.3.4\n",
            "2023-12-10 00:50:27.137867: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-10 00:50:27.137950: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-10 00:50:27.137988: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-10 00:50:27.146876: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-10 00:50:28.379683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.6.0\n",
            "    Uninstalling en-core-web-sm-3.6.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.6.0\n",
            "Successfully installed en-core-web-sm-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install pylangacq\n",
        "!pip install pronouncing\n",
        "!pip install --upgrade spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "trqTuOQ0In34"
      },
      "outputs": [],
      "source": [
        "import pylangacq\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import cmudict\n",
        "import numpy as np\n",
        "import spacy\n",
        "import pronouncing\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leemos los archivos\n"
      ],
      "metadata": {
        "id": "8Rm_6QvmNoB-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8KSiLwJAp_CR"
      },
      "outputs": [],
      "source": [
        "MOTH1=pylangacq.read_chat(\"001.cha\")\n",
        "MOTH2=pylangacq.read_chat(\"003.cha\")\n",
        "MOTH3=pylangacq.read_chat(\"004.cha\")\n",
        "MOTH4=pylangacq.read_chat(\"007.cha\")\n",
        "MOTH5=pylangacq.read_chat(\"008.cha\")\n",
        "MOTH6=pylangacq.read_chat(\"009.cha\")\n",
        "MOTH7=pylangacq.read_chat(\"013.cha\")\n",
        "MOTH8=pylangacq.read_chat(\"014.cha\")\n",
        "MOTH9=pylangacq.read_chat(\"015.cha\")\n",
        "MOTH10=pylangacq.read_chat(\"016.cha\")\n",
        "MOTH11=pylangacq.read_chat(\"019.cha\")\n",
        "MOTH12=pylangacq.read_chat(\"020.cha\")\n",
        "MOTH13=pylangacq.read_chat(\"024.cha\")\n",
        "MOTH14=pylangacq.read_chat(\"025.cha\")\n",
        "MOTH15=pylangacq.read_chat(\"027.cha\")\n",
        "MOTH16=pylangacq.read_chat(\"030.cha\")\n",
        "MOTH17=pylangacq.read_chat(\"033.cha\")\n",
        "MOTH18=pylangacq.read_chat(\"035.cha\")\n",
        "MOTH19=pylangacq.read_chat(\"038.cha\")\n",
        "MOTH20=pylangacq.read_chat(\"040.cha\")\n",
        "MOTH21=pylangacq.read_chat(\"041.cha\")\n",
        "MOTH22=pylangacq.read_chat(\"043.cha\")\n",
        "MOTH23=pylangacq.read_chat(\"046.cha\")\n",
        "MOTH24=pylangacq.read_chat(\"050.cha\")\n",
        "MOTH25=pylangacq.read_chat(\"051.cha\")\n",
        "MOTH26=pylangacq.read_chat(\"052.cha\")\n",
        "MOTH27=pylangacq.read_chat(\"054.cha\")\n",
        "MOTH28=pylangacq.read_chat(\"056.cha\")\n",
        "MOTH29=pylangacq.read_chat(\"057.cha\")\n",
        "MOTH30=pylangacq.read_chat(\"059.cha\")\n",
        "MOTH31=pylangacq.read_chat(\"060.cha\")\n",
        "MOTH32=pylangacq.read_chat(\"061.cha\")\n",
        "MOTH33=pylangacq.read_chat(\"062.cha\")\n",
        "MOTH34=pylangacq.read_chat(\"064.cha\")\n",
        "MOTH35=pylangacq.read_chat(\"066.cha\")\n",
        "MOTH36=pylangacq.read_chat(\"068.cha\")\n",
        "MOTH37=pylangacq.read_chat(\"069.cha\")\n",
        "MOTH38=pylangacq.read_chat(\"070.cha\")\n",
        "MOTH39=pylangacq.read_chat(\"073.cha\")\n",
        "MOTH40=pylangacq.read_chat(\"075.cha\")\n",
        "MOTH41=pylangacq.read_chat(\"076.cha\")\n",
        "MOTH42=pylangacq.read_chat(\"077.cha\")\n",
        "MOTH43=pylangacq.read_chat(\"080.cha\")\n",
        "MOTH44=pylangacq.read_chat(\"081.cha\")\n",
        "MOTH45=pylangacq.read_chat(\"086.cha\")\n",
        "MOTH46=pylangacq.read_chat(\"089.cha\")\n",
        "MOTH47=pylangacq.read_chat(\"090.cha\")\n",
        "MOTH48=pylangacq.read_chat(\"091.cha\")\n",
        "MOTH49=pylangacq.read_chat(\"096.cha\")\n",
        "MOTH50=pylangacq.read_chat(\"098.cha\")\n",
        "MOTH51=pylangacq.read_chat(\"100.cha\")\n",
        "MOTH52=pylangacq.read_chat(\"101.cha\")\n",
        "MOTH53=pylangacq.read_chat(\"102.cha\")\n",
        "MOTH54=pylangacq.read_chat(\"103.cha\")\n",
        "MOTH55=pylangacq.read_chat(\"105.cha\")\n",
        "MOTH56=pylangacq.read_chat(\"108.cha\")\n",
        "MOTH57=pylangacq.read_chat(\"109.cha\")\n",
        "MOTH58=pylangacq.read_chat(\"110.cha\")\n",
        "MOTH59=pylangacq.read_chat(\"112.cha\")\n",
        "MOTH60=pylangacq.read_chat(\"113.cha\")\n",
        "MOTH61=pylangacq.read_chat(\"116.cha\")\n",
        "MOTH62=pylangacq.read_chat(\"119.cha\")\n",
        "MOTH63=pylangacq.read_chat(\"121.cha\")\n",
        "MOTH64=pylangacq.read_chat(\"123.cha\")\n",
        "MOTH65=pylangacq.read_chat(\"125.cha\")\n",
        "MOTH66=pylangacq.read_chat(\"128.cha\")\n",
        "MOTH67=pylangacq.read_chat(\"129.cha\")\n",
        "MOTH68=pylangacq.read_chat(\"131.cha\")\n",
        "MOTH69=pylangacq.read_chat(\"132.cha\")\n",
        "MOTH70=pylangacq.read_chat(\"133.cha\")\n",
        "MOTH71=pylangacq.read_chat(\"139.cha\")\n",
        "MOTH72=pylangacq.read_chat(\"140.cha\")\n",
        "MOTH73=pylangacq.read_chat(\"145.cha\")\n",
        "MOTH74=pylangacq.read_chat(\"146.cha\")\n",
        "MOTH75=pylangacq.read_chat(\"148.cha\")\n",
        "\n",
        "MOTH = [MOTH1,MOTH2,MOTH3,MOTH4,MOTH5,MOTH6,MOTH7,MOTH8,MOTH9,MOTH10,MOTH11,\n",
        "        MOTH12,MOTH13,MOTH14,MOTH15,MOTH16,MOTH17,MOTH18,MOTH19,MOTH20,MOTH21,\n",
        "        MOTH22,MOTH23,MOTH24,MOTH25,MOTH26,MOTH27,MOTH28,MOTH29,MOTH30,MOTH31,\n",
        "        MOTH32,MOTH33,MOTH34,MOTH35,MOTH36,MOTH37,MOTH38,MOTH39,MOTH40,MOTH41,\n",
        "        MOTH42,MOTH43,MOTH44,MOTH45,MOTH46,MOTH47,MOTH48,MOTH49,MOTH50,MOTH51,\n",
        "        MOTH52,MOTH53,MOTH54,MOTH55,MOTH56,MOTH57,MOTH58,MOTH59,MOTH60,MOTH61,\n",
        "        MOTH62,MOTH63,MOTH64,MOTH65,MOTH66,MOTH67,MOTH68,MOTH69,MOTH70,MOTH71,\n",
        "        MOTH72,MOTH73,MOTH74,MOTH75]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos las palabras de cada uno"
      ],
      "metadata": {
        "id": "yw0bNnJ_NquF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iLkjS6d-njxb"
      },
      "outputs": [],
      "source": [
        "words=[]\n",
        "for j in MOTH:\n",
        "  token = [a.tokens for a in j.utterances()]\n",
        "  for t in token:\n",
        "    for tok in t:\n",
        "      words.append(tok.word)\n",
        "\n",
        "words=[w.upper() for w in words]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpiamos los datos"
      ],
      "metadata": {
        "id": "1GJznJYlNxO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbNNNZXn1WPm",
        "outputId": "70e0ba08-3364-4e6b-90f7-02e9115ef32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['!' ',' '.' '0ARE' '?' 'B' 'C' 'CLITIC' 'E' 'I' 'K' 'M' 'O' 'P' 'S']\n"
          ]
        }
      ],
      "source": [
        "borrar=[i for i in words if not re.search(\"^[A-Za-z].*[A-Za-z]$\",i)]+[\"CLITIC\"]\n",
        "myList = np.unique(list(filter(('A').__ne__, borrar)))\n",
        "\n",
        "print(myList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiATKVaR5r1l",
        "outputId": "55e9c703-c617-46f3-b8da-a1a709e6ca54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1999"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ],
      "source": [
        "for i in myList:\n",
        "  words =list(filter((i).__ne__, words))\n",
        "len(set(words))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se lematizan las palabras"
      ],
      "metadata": {
        "id": "KhExrvUPN4_n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UE-rR66XyqOe"
      },
      "outputs": [],
      "source": [
        "nlp=spacy.load('en_core_web_sm')\n",
        "cadena = \"\"\n",
        "for i in words:\n",
        "  cadena += i.lower() + \" \"\n",
        "doc = nlp(cadena)\n",
        "sing1 = []\n",
        "# Itera a través de los tokens y modifica las palabras en plural\n",
        "for token in doc:\n",
        "    if token.tag_ == \"NNS\":\n",
        "        # Verificamos si el token es un sustantivo en plural (NNS)\n",
        "        # Reemplazamos el token con su forma singular (lema)\n",
        "        singular = token.lemma_\n",
        "        sing1.append(singular)\n",
        "    else:\n",
        "        # Mantenemos las demás palabras en su forma original\n",
        "        sing1.append(token.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oXv8yaXPO4uw"
      },
      "outputs": [],
      "source": [
        "cadena2 = \"\"\n",
        "for i in sing1:\n",
        "  cadena2 += i + \" \"\n",
        "doc1 = nlp(cadena2)\n",
        "lemmas = [tok.lemma_ for tok in doc1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(lemmas).head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tzGI53GVOC9A",
        "outputId": "4422e82a-948f-42ac-9bd5-357f8e259fe2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0\n",
              "0         be\n",
              "1         we\n",
              "2         go\n",
              "3         to\n",
              "4      leave\n",
              "5        the\n",
              "6     camera\n",
              "7      alone\n",
              "8         or\n",
              "9         be\n",
              "10       you\n",
              "11        to\n",
              "12      busy\n",
              "13      wave\n",
              "14        at\n",
              "15       the\n",
              "16    camera\n",
              "17      okay\n",
              "18       see\n",
              "19  michelle\n",
              "20        be\n",
              "21        go\n",
              "22        to\n",
              "23        go\n",
              "24       and\n",
              "25      hide\n",
              "26       for\n",
              "27         a\n",
              "28       bit\n",
              "29       now\n",
              "30       she\n",
              "31      want\n",
              "32        to\n",
              "33       see\n",
              "34       you\n",
              "35      play\n",
              "36       she\n",
              "37        do\n",
              "38       not\n",
              "39     wanna\n",
              "40       see\n",
              "41       you\n",
              "42   destroy\n",
              "43       her\n",
              "44    camera\n",
              "45       she\n",
              "46      want\n",
              "47        to\n",
              "48       see\n",
              "49       how"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06b58ef1-8611-4de6-9c10-3792b5dd1881\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>leave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>camera</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>alone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>or</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>busy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>wave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>at</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>camera</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>okay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>see</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>michelle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>hide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>bit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>she</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>want</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>see</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>she</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>do</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>not</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>wanna</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>see</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>destroy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>her</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>camera</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>she</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>want</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>see</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>how</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06b58ef1-8611-4de6-9c10-3792b5dd1881')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06b58ef1-8611-4de6-9c10-3792b5dd1881 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06b58ef1-8611-4de6-9c10-3792b5dd1881');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0fc646b9-c38a-431d-b3b4-e04e4b210ee5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fc646b9-c38a-431d-b3b4-e04e4b210ee5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0fc646b9-c38a-431d-b3b4-e04e4b210ee5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fonetizamos el texto y eliminamos las palabras que no tienen fonetización"
      ],
      "metadata": {
        "id": "E_QCVzllOZ-A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCk56euR0jU9",
        "outputId": "647cf1f9-140e-4fd1-ae07-59a1ac8df483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('cmudict')\n",
        "\n",
        "# Cargar el diccionario CMU Pronouncing\n",
        "pronunciacion_diccionario = cmudict.dict()\n",
        "\n",
        "def fonetizar_palabra_cmudict(palabra):\n",
        "    # Convertir la palabra a minúsculas\n",
        "    palabra = palabra.lower()\n",
        "\n",
        "    # Obtener la pronunciación de la palabra desde el diccionario CMU Pronouncing\n",
        "    pronunciacion = pronunciacion_diccionario.get(palabra, None)\n",
        "\n",
        "    return pronunciacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TQ0qDB3T02St"
      },
      "outputs": [],
      "source": [
        "# Fonetizar\n",
        "for i in lemmas:\n",
        "  fon = fonetizar_palabra_cmudict(i.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "O8qvoLvA9fdE"
      },
      "outputs": [],
      "source": [
        "phon=[]\n",
        "nophon=[]\n",
        "for i in lemmas:\n",
        "  phon.append(fonetizar_palabra_cmudict(i.lower()))\n",
        "  if fonetizar_palabra_cmudict(i.lower())==None:\n",
        "    nophon.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tibAtJYv_n3m"
      },
      "outputs": [],
      "source": [
        "fonetizar = list(set(nophon)) # los que no tienen fonetizacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Uft9vaFc-gnX"
      },
      "outputs": [],
      "source": [
        "for i in fonetizar: # se eliminan\n",
        "  lemmas =list(filter((i).__ne__, lemmas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "FK_E2Ceb-qol"
      },
      "outputs": [],
      "source": [
        "phon=[]\n",
        "for i in lemmas:\n",
        "  phon.append(fonetizar_palabra_cmudict(i.lower())[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "tWf7Vd3B_9Jz"
      },
      "outputs": [],
      "source": [
        "fonemas_final=[] # se hace homogeneo el formato de fonemas\n",
        "for word in phon:\n",
        "  palabra = []\n",
        "  for fon in word:\n",
        "    fon = fon.replace(\"0\",\"\")\n",
        "    fon = fon.replace(\"1\",\"\")\n",
        "    fon = fon.replace(\"2\",\"\")\n",
        "    palabra.append(fon)\n",
        "  fonemas_final.append(palabra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "eUThK-i1CGFI"
      },
      "outputs": [],
      "source": [
        "fonemas = [fon for fon in fonemas_final]\n",
        "fon_2 = [str(fon)[2:-2].replace(\"', '\",\"_\") for fon in fonemas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Ed_XPvunAERW"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df[\"Palabra\"]=lemmas\n",
        "df[\"Fonema\"]=fonemas\n",
        "df[\"Fonema 2\"]=fon_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rq8AWQZGAnGk",
        "outputId": "f7298c69-607f-4a96-b415-11ef1ede5844"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Palabra         Fonema  Fonema 2\n",
              "0          be        [B, IY]      B_IY\n",
              "1          we        [W, IY]      W_IY\n",
              "2          go        [G, OW]      G_OW\n",
              "3          to        [T, UW]      T_UW\n",
              "4       leave     [L, IY, V]    L_IY_V\n",
              "...       ...            ...       ...\n",
              "38060     you        [Y, UW]      Y_UW\n",
              "38061    want  [W, AA, N, T]  W_AA_N_T\n",
              "38062    this    [DH, IH, S]   DH_IH_S\n",
              "38063    okay    [OW, K, EY]   OW_K_EY\n",
              "38064    then    [DH, EH, N]   DH_EH_N\n",
              "\n",
              "[38065 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-010d7b5d-0913-4ca5-99bb-752013267b7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Palabra</th>\n",
              "      <th>Fonema</th>\n",
              "      <th>Fonema 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>be</td>\n",
              "      <td>[B, IY]</td>\n",
              "      <td>B_IY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>we</td>\n",
              "      <td>[W, IY]</td>\n",
              "      <td>W_IY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>go</td>\n",
              "      <td>[G, OW]</td>\n",
              "      <td>G_OW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>[T, UW]</td>\n",
              "      <td>T_UW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>leave</td>\n",
              "      <td>[L, IY, V]</td>\n",
              "      <td>L_IY_V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38060</th>\n",
              "      <td>you</td>\n",
              "      <td>[Y, UW]</td>\n",
              "      <td>Y_UW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38061</th>\n",
              "      <td>want</td>\n",
              "      <td>[W, AA, N, T]</td>\n",
              "      <td>W_AA_N_T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38062</th>\n",
              "      <td>this</td>\n",
              "      <td>[DH, IH, S]</td>\n",
              "      <td>DH_IH_S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38063</th>\n",
              "      <td>okay</td>\n",
              "      <td>[OW, K, EY]</td>\n",
              "      <td>OW_K_EY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38064</th>\n",
              "      <td>then</td>\n",
              "      <td>[DH, EH, N]</td>\n",
              "      <td>DH_EH_N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38065 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-010d7b5d-0913-4ca5-99bb-752013267b7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-010d7b5d-0913-4ca5-99bb-752013267b7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-010d7b5d-0913-4ca5-99bb-752013267b7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a04cc6bb-eeac-4fb8-99f2-226cdaad242d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a04cc6bb-eeac-4fb8-99f2-226cdaad242d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a04cc6bb-eeac-4fb8-99f2-226cdaad242d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "HbfWa2tkB7v4"
      },
      "outputs": [],
      "source": [
        "ids = ['anne', 'aran', 'becky', 'carl', 'domin', 'gail', 'joel', 'john', 'liz', 'nic', 'ruth', 'warr']\n",
        "phonemes = [\"AA\", \"AE\", \"AH\", \"AO\", \"AW\", \"AY\", \"B\", \"CH\", \"D\", \"DH\", \"EH\", \"ER\", \"EY\", \"F\", \"G\", \"HH\", \"IH\", \"IY\", \"JH\", \"K\", \"L\", \"M\", \"N\", \"NG\", \"OW\", \"OY\", \"P\", \"R\", \"S\",\"SH\", \"T\", \"TH\", \"UH\", \"UW\", \"V\", \"W\", \"Y\", \"Z\", \"ZH\", \"<START>\", \"<END>\", \"<PAD>\"]\n",
        "vowels = [\"AA\", \"AE\", \"AH\", \"AO\", \"AW\", \"AY\", \"EH\", \"ER\", \"EY\", \"IH\", \"IY\", \"OW\", \"OY\", \"UH\", \"UW\"]\n",
        "num_phonemes = len(phonemes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "I37HNkoiGhLP"
      },
      "outputs": [],
      "source": [
        "# vectores para cada fonema\n",
        "def encode_phon_one_hot(phon):\n",
        "    vec = np.zeros(len(phonemes))\n",
        "    vec[phonemes.index(phon)] = 1\n",
        "    return vec\n",
        "\n",
        "# regresa la posición del fonema\n",
        "def decode_phon_one_hot(vec):\n",
        "    index = np.argmax(vec)\n",
        "    return phonemes[index]\n",
        "\n",
        "# convierte una secuencia de fonemas a palabra\n",
        "def vec_to_word(seq):\n",
        "    seq = seq[np.sum(seq, 1) == 1]\n",
        "    return [decode_phon_one_hot(vec) for vec in seq]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se leen los datos para entrenar el modelo previamente entrenado"
      ],
      "metadata": {
        "id": "puLE-bA6QI8J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Ho5hh5QWnGJd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c16de97b-ad66-4395-a0ca-a764684a77b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  stage              phon_str                           phon\n",
              "17760  anne      1                    AA                           [AA]\n",
              "17761  anne      1                  AA_N                        [AA, N]\n",
              "17762  anne      1             AA_N_T_UW                 [AA, N, T, UW]\n",
              "17763  anne      1                  AA_R                        [AA, R]\n",
              "17764  anne      1           AA_R_AH_N_T              [AA, R, AH, N, T]\n",
              "...     ...    ...                   ...                            ...\n",
              "51952  warr     20  TH_ER_M_AA_M_AH_T_ER  [TH, ER, M, AA, M, AH, T, ER]\n",
              "51953  warr     20        TH_IH_K_N_AH_S          [TH, IH, K, N, AH, S]\n",
              "51954  warr     20                W_AO_R                     [W, AO, R]\n",
              "51955  warr     20   W_EH_L_IH_NG_T_AH_N   [W, EH, L, IH, NG, T, AH, N]\n",
              "51956  warr     20  W_IH_N_IY_DH_AH_P_UW  [W, IH, N, IY, DH, AH, P, UW]\n",
              "\n",
              "[34197 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9599fa2-18fa-400f-965f-1767f760fd94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>stage</th>\n",
              "      <th>phon_str</th>\n",
              "      <th>phon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17760</th>\n",
              "      <td>anne</td>\n",
              "      <td>1</td>\n",
              "      <td>AA</td>\n",
              "      <td>[AA]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17761</th>\n",
              "      <td>anne</td>\n",
              "      <td>1</td>\n",
              "      <td>AA_N</td>\n",
              "      <td>[AA, N]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17762</th>\n",
              "      <td>anne</td>\n",
              "      <td>1</td>\n",
              "      <td>AA_N_T_UW</td>\n",
              "      <td>[AA, N, T, UW]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17763</th>\n",
              "      <td>anne</td>\n",
              "      <td>1</td>\n",
              "      <td>AA_R</td>\n",
              "      <td>[AA, R]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17764</th>\n",
              "      <td>anne</td>\n",
              "      <td>1</td>\n",
              "      <td>AA_R_AH_N_T</td>\n",
              "      <td>[AA, R, AH, N, T]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51952</th>\n",
              "      <td>warr</td>\n",
              "      <td>20</td>\n",
              "      <td>TH_ER_M_AA_M_AH_T_ER</td>\n",
              "      <td>[TH, ER, M, AA, M, AH, T, ER]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51953</th>\n",
              "      <td>warr</td>\n",
              "      <td>20</td>\n",
              "      <td>TH_IH_K_N_AH_S</td>\n",
              "      <td>[TH, IH, K, N, AH, S]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51954</th>\n",
              "      <td>warr</td>\n",
              "      <td>20</td>\n",
              "      <td>W_AO_R</td>\n",
              "      <td>[W, AO, R]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51955</th>\n",
              "      <td>warr</td>\n",
              "      <td>20</td>\n",
              "      <td>W_EH_L_IH_NG_T_AH_N</td>\n",
              "      <td>[W, EH, L, IH, NG, T, AH, N]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51956</th>\n",
              "      <td>warr</td>\n",
              "      <td>20</td>\n",
              "      <td>W_IH_N_IY_DH_AH_P_UW</td>\n",
              "      <td>[W, IH, N, IY, DH, AH, P, UW]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34197 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9599fa2-18fa-400f-965f-1767f760fd94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9599fa2-18fa-400f-965f-1767f760fd94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9599fa2-18fa-400f-965f-1767f760fd94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f72f0ff0-dbac-495a-8df9-e213bb7c7bc8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f72f0ff0-dbac-495a-8df9-e213bb7c7bc8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f72f0ff0-dbac-495a-8df9-e213bb7c7bc8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "manch_typ = pd.read_csv(\"manch_typ.csv\")\n",
        "manch_typ = manch_typ.rename(columns={'phon' : 'phon_str'})\n",
        "madres = manch_typ.query(\"set=='MOT'\").loc[:,[\"id\",\"stage\",\"phon_str\"]]\n",
        "fonemas3 = [fon.split(\"_\") for fon in list(madres[\"phon_str\"])]\n",
        "madres[\"phon\"]=fonemas3\n",
        "madres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "rFa-hRSiHRZC"
      },
      "outputs": [],
      "source": [
        "words_ptrain = np.unique(df['Fonema'].to_numpy())\n",
        "words_ptrain_str = ['_'.join(word) for word in words_ptrain]\n",
        "\n",
        "words_train = np.unique(madres['phon'].to_numpy())\n",
        "words_train_str = ['_'.join(word) for word in words_train]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_train,words_ptrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkFEsY1UQu1L",
        "outputId": "92ae541b-9dbf-4426-8d22-d25cbde43dc6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([list(['AA']), list(['AA', 'AA']), list(['AA', 'AA', 'AA']), ...,\n",
              "        list(['Z', 'UW', 'M', 'IH', 'NG']), list(['Z', 'UW', 'M', 'Z']),\n",
              "        list(['Z', 'Z'])], dtype=object),\n",
              " array([list(['AA']), list(['AA', 'B', 'V', 'IY', 'AH', 'S', 'L', 'IY']),\n",
              "        list(['AA', 'K', 'T', 'AH', 'P', 'UH', 'S']), ...,\n",
              "        list(['Z', 'AY', 'L', 'AH', 'F', 'OW', 'N']),\n",
              "        list(['Z', 'IY', 'B', 'R', 'AH']), list(['Z', 'UW'])], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "N0vY7bW3HfiN"
      },
      "outputs": [],
      "source": [
        "max_word_length_input = max([len(word) for word in words_train])\n",
        "max_word_length_target = max_word_length_input + 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preentreno del modelo con el corpus fonetizado"
      ],
      "metadata": {
        "id": "tVZ35xSlRXzj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "4CfKIHYrLn2D"
      },
      "outputs": [],
      "source": [
        "def build_training_model(latent_dim):\n",
        "    encoder_inputs = Input(shape=(None, num_phonemes))\n",
        "    encoder = LSTM(latent_dim, return_state=True)\n",
        "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "    # We discard `encoder_outputs` and only keep the states.\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Set up the decoder, using `encoder_states` as initial state.\n",
        "    decoder_inputs = Input(shape=(None, num_phonemes))\n",
        "    # We set up our decoder to return full output sequences,\n",
        "    # and to return internal states as well. We don't use the\n",
        "    # return states in the training model, but we will use them in inference.\n",
        "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(num_phonemes, activation='softmax')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Define the model that will turn\n",
        "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "    return Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "5GdZ8jHGLtLI"
      },
      "outputs": [],
      "source": [
        "def build_inference_model(model, latent_dim):\n",
        "    encoder_inputs = model.input[0]  # input_1\n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "    encoder_states = [state_h_enc, state_c_enc]\n",
        "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_inputs = model.input[1]  # input_2\n",
        "    decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "    decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    decoder_lstm = model.layers[3]\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs\n",
        "    )\n",
        "    decoder_states = [state_h_dec, state_c_dec]\n",
        "    decoder_dense = model.layers[4]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = keras.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        "    )\n",
        "\n",
        "    return (encoder_model, decoder_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "5oOQQNsLMGs_"
      },
      "outputs": [],
      "source": [
        "def train_model(model, epochs, e_input, d_input, d_target):\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit([e_input, d_input], d_target,\n",
        "              batch_size=64,\n",
        "              epochs=epochs,\n",
        "              validation_split=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "htVXqKMEMXAa"
      },
      "outputs": [],
      "source": [
        "def predict_words(encoder_model, decoder_model, words):\n",
        "    encoder_input = np.full((len(words), max_word_length_input, num_phonemes), encode_phon_one_hot(\"<PAD>\"), dtype='float32')\n",
        "    for i, word in enumerate(words):\n",
        "        encoder_input[i,:len(word)] = [encode_phon_one_hot(phon) for phon in word]\n",
        "        encoder_input[i] = np.flip(encoder_input[i])\n",
        "\n",
        "    states = encoder_model.predict(encoder_input, verbose = 0)\n",
        "\n",
        "    predicted_phons = np.array(['<START>' for _ in range(len(words))])\n",
        "    predicted_words = np.zeros((len(words), max_word_length_input), dtype='object')\n",
        "\n",
        "\n",
        "    for i in range(max_word_length_input):\n",
        "        decoder_input = np.zeros((len(words), 1, num_phonemes), dtype='float32')\n",
        "        decoder_input = np.array([[encode_phon_one_hot(phon)] for phon in predicted_phons])\n",
        "\n",
        "        decoder_output, h, c = decoder_model.predict([decoder_input] + states, verbose = 0)\n",
        "\n",
        "        states = [h, c]\n",
        "\n",
        "\n",
        "        predicted_phons = [decode_phon_one_hot(decoder_output[j,0]) for j in range(len(words))]\n",
        "        predicted_words[:,i] = predicted_phons\n",
        "\n",
        "    return predicted_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "VjI4rVcDMpLA"
      },
      "outputs": [],
      "source": [
        "def evaluate_model2(encoder, decoder,words):\n",
        "    words_learned = list()\n",
        "    predictions = predict_words(encoder, decoder, words)\n",
        "    for i in range(len(words)):\n",
        "        pred = predictions[i]\n",
        "        pred = pred[(pred != '<END>')&(pred != '<PAD>')]\n",
        "        if np.array_equal(words[i], pred):\n",
        "            words_learned.append(pred)\n",
        "    print(\"Words learned: {}\".format(len(words_learned)))\n",
        "    print(\"Percentage: {}\".format(len(words_learned)/len(words)))\n",
        "    return words_learned"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preentreno con 15 capas"
      ],
      "metadata": {
        "id": "e6NbDP2FSefj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare Datasets\n",
        "input_words = df.copy()\n",
        "input_words = input_words['Fonema']\n",
        "target_words = input_words.copy()\n",
        "target_words = target_words.transform(lambda word : [\"<START>\"] + word + [\"<END>\"])\n",
        "num_words = 51956"
      ],
      "metadata": {
        "id": "9a98MmjuS_jg"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = np.zeros((num_words, max_word_length_input, num_phonemes), dtype=\"float32\")\n",
        "decoder_input = np.zeros((num_words, max_word_length_target, num_phonemes), dtype=\"float32\")\n",
        "decoder_target = np.zeros((num_words, max_word_length_target, num_phonemes), dtype=\"float32\")"
      ],
      "metadata": {
        "id": "pKlERtqzTEAj"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_word, target_word) in enumerate(zip(input_words, target_words)):\n",
        "  encoder_input[i] = [encode_phon_one_hot(\"<PAD>\") for _ in range(max_word_length_input)]\n",
        "\n",
        "  input_word = [encode_phon_one_hot(phon) for phon in input_word]\n",
        "  encoder_input[i, :len(input_word)] = input_word\n",
        "\n",
        "  #Reverse Inputs\n",
        "  encoder_input[i] = np.flip(encoder_input[i])\n",
        "\n",
        "\n",
        "  decoder_input[i] = [encode_phon_one_hot(\"<PAD>\") for _ in range(max_word_length_target)]\n",
        "  decoder_target[i] = [encode_phon_one_hot(\"<PAD>\") for _ in range(max_word_length_target)]\n",
        "\n",
        "  target_word = [encode_phon_one_hot(phon) for phon in target_word]\n",
        "  decoder_input[i, :len(target_word)] = target_word\n",
        "  decoder_target[i, :len(target_word) - 1] = target_word[1:]"
      ],
      "metadata": {
        "id": "0FrhcwV0THpW"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 32\n",
        "model = build_training_model(latent_dim)\n",
        "inference_models = build_inference_model(model, latent_dim)"
      ],
      "metadata": {
        "id": "hbserCFYS6b5"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adK2QQ3hMrnk",
        "outputId": "beddff77-b5d7-4fae-808a-04659a3a2073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "812/812 [==============================] - 35s 38ms/step - loss: 0.3832 - accuracy: 0.6515\n",
            "Epoch 2/15\n",
            "812/812 [==============================] - 28s 34ms/step - loss: 0.1799 - accuracy: 0.6945\n",
            "Epoch 3/15\n",
            "812/812 [==============================] - 28s 34ms/step - loss: 0.1376 - accuracy: 0.7073\n",
            "Epoch 4/15\n",
            "812/812 [==============================] - 28s 34ms/step - loss: 0.1147 - accuracy: 0.7134\n",
            "Epoch 5/15\n",
            "812/812 [==============================] - 27s 34ms/step - loss: 0.0997 - accuracy: 0.7174\n",
            "Epoch 6/15\n",
            "812/812 [==============================] - 28s 34ms/step - loss: 0.0886 - accuracy: 0.7202\n",
            "Epoch 7/15\n",
            "812/812 [==============================] - 26s 32ms/step - loss: 0.0798 - accuracy: 0.7226\n",
            "Epoch 8/15\n",
            "812/812 [==============================] - 27s 34ms/step - loss: 0.0723 - accuracy: 0.7246\n",
            "Epoch 9/15\n",
            "812/812 [==============================] - 28s 35ms/step - loss: 0.0668 - accuracy: 0.7259\n",
            "Epoch 10/15\n",
            "812/812 [==============================] - 27s 34ms/step - loss: 0.0623 - accuracy: 0.7268\n",
            "Epoch 11/15\n",
            "812/812 [==============================] - 28s 34ms/step - loss: 0.0588 - accuracy: 0.7274\n",
            "Epoch 12/15\n",
            "812/812 [==============================] - 28s 34ms/step - loss: 0.0558 - accuracy: 0.7277\n",
            "Epoch 13/15\n",
            "812/812 [==============================] - 28s 34ms/step - loss: 0.0529 - accuracy: 0.7281\n",
            "Epoch 14/15\n",
            "812/812 [==============================] - 27s 33ms/step - loss: 0.0507 - accuracy: 0.7286\n",
            "Epoch 15/15\n",
            "812/812 [==============================] - 26s 32ms/step - loss: 0.0485 - accuracy: 0.7290\n",
            "Words learned: 625\n",
            "Percentage: 0.4633061527057079\n"
          ]
        }
      ],
      "source": [
        "already_learned = set()\n",
        "train_model(model, 15, encoder_input, decoder_input, decoder_target)\n",
        "words_learned = evaluate_model2(inference_models[0], inference_models[1],words_ptrain)\n",
        "for word in words_learned:\n",
        "    word_str = '_'.join(word)\n",
        "    if not (word_str in already_learned):\n",
        "        already_learned.add(word_str)\n",
        "del encoder_input\n",
        "del decoder_input\n",
        "del decoder_target\n",
        "del words_learned"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se simula el aprendizaje entrenando la red preentrenada, con las palabras que las madres les dicen a cada niño y en cada etapa"
      ],
      "metadata": {
        "id": "_0D5VfU-TfR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "5d5bwMEaUWig"
      },
      "outputs": [],
      "source": [
        "def get_dataset(id, stage):\n",
        "    #Prepare Datasets\n",
        "    input_words = madres.copy()\n",
        "    input_words = input_words[(input_words.id == id) & (input_words.stage == stage)][['phon']]\n",
        "\n",
        "    target_words = input_words.copy()\n",
        "    target_words['phon'] = target_words['phon'].transform(lambda word : [\"<START>\"] + word + [\"<END>\"])\n",
        "\n",
        "    num_words = len(input_words)\n",
        "\n",
        "    encoder_input = np.zeros((num_words, max_word_length_input, num_phonemes), dtype=\"float32\")\n",
        "    decoder_input = np.zeros((num_words, max_word_length_target, num_phonemes), dtype=\"float32\")\n",
        "    decoder_target = np.zeros((num_words, max_word_length_target, num_phonemes), dtype=\"float32\")\n",
        "\n",
        "    for i, (input_word, target_word) in enumerate(zip(input_words['phon'], target_words['phon'])):\n",
        "        encoder_input[i] = [encode_phon_one_hot(\"<PAD>\") for _ in range(max_word_length_input)]\n",
        "\n",
        "        input_word = [encode_phon_one_hot(phon) for phon in input_word]\n",
        "        encoder_input[i, :len(input_word)] = input_word\n",
        "\n",
        "        #Reverse Inputs\n",
        "        encoder_input[i] = np.flip(encoder_input[i])\n",
        "\n",
        "\n",
        "        decoder_input[i] = [encode_phon_one_hot(\"<PAD>\") for _ in range(max_word_length_target)]\n",
        "        decoder_target[i] = [encode_phon_one_hot(\"<PAD>\") for _ in range(max_word_length_target)]\n",
        "\n",
        "        target_word = [encode_phon_one_hot(phon) for phon in target_word]\n",
        "        decoder_input[i, :len(target_word)] = target_word\n",
        "        decoder_target[i, :len(target_word) - 1] = target_word[1:]\n",
        "\n",
        "    return encoder_input, decoder_input, decoder_target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea una copia del modelo preentrenado por cada uno de los niños  y se entrena en cada etapa"
      ],
      "metadata": {
        "id": "GxnAttn9T-7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "tkMyjmWBbxJ5"
      },
      "outputs": [],
      "source": [
        "latent_dim = 32\n",
        "models = [tf.keras.models.clone_model(model) for id in ids]\n",
        "inference_models = [build_inference_model(model, latent_dim) for model in models]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ibkQEnPcgmDO",
        "outputId": "5524135e-8c14-4b86-e8f7-5e5977b3a3a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10/10 [==============================] - 4s 31ms/step - loss: 3.6560 - accuracy: 0.1699\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.4528 - accuracy: 0.8318\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 2.9645 - accuracy: 0.8326\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 1.9771 - accuracy: 0.8325\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.3504 - accuracy: 0.8325\n",
            "evaluating model anne at stage 1\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "4/4 [==============================] - 5s 66ms/step - loss: 1.1986 - accuracy: 0.8079\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.1032 - accuracy: 0.8079\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0236 - accuracy: 0.8079\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9626 - accuracy: 0.8079\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.9126 - accuracy: 0.8079\n",
            "evaluating model anne at stage 2\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "4/4 [==============================] - 5s 51ms/step - loss: 0.8887 - accuracy: 0.8085\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.8553 - accuracy: 0.8085\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.8300 - accuracy: 0.8085\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.8069 - accuracy: 0.8085\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.7898 - accuracy: 0.8085\n",
            "evaluating model anne at stage 3\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 4s 35ms/step - loss: 0.8419 - accuracy: 0.7901\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8270 - accuracy: 0.7901\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8150 - accuracy: 0.7901\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8006 - accuracy: 0.7901\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.7940 - accuracy: 0.7901\n",
            "evaluating model anne at stage 4\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 4s 31ms/step - loss: 0.7323 - accuracy: 0.8047\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.7186 - accuracy: 0.8047\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.7095 - accuracy: 0.8047\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.7076 - accuracy: 0.8047\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6982 - accuracy: 0.8047\n",
            "evaluating model anne at stage 5\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 39ms/step - loss: 0.7463 - accuracy: 0.7952\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.7297 - accuracy: 0.7952\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7349 - accuracy: 0.7952\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7240 - accuracy: 0.7952\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7231 - accuracy: 0.7952\n",
            "evaluating model anne at stage 6\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 34ms/step - loss: 0.7548 - accuracy: 0.7871\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7466 - accuracy: 0.7864\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7490 - accuracy: 0.7864\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7387 - accuracy: 0.7864\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7384 - accuracy: 0.7864\n",
            "evaluating model anne at stage 7\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 39ms/step - loss: 0.7247 - accuracy: 0.7907\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7203 - accuracy: 0.7937\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7158 - accuracy: 0.7915\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7130 - accuracy: 0.7907\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7079 - accuracy: 0.7926\n",
            "evaluating model anne at stage 8\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 50ms/step - loss: 0.7244 - accuracy: 0.7949\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7147 - accuracy: 0.7920\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7167 - accuracy: 0.8042\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7071 - accuracy: 0.7946\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7081 - accuracy: 0.7901\n",
            "evaluating model anne at stage 9\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 36ms/step - loss: 0.7663 - accuracy: 0.7878\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7583 - accuracy: 0.7902\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7609 - accuracy: 0.7816\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7496 - accuracy: 0.7847\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7470 - accuracy: 0.7980\n",
            "evaluating model anne at stage 10\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 34ms/step - loss: 0.7984 - accuracy: 0.7734\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.7885 - accuracy: 0.7825\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7879 - accuracy: 0.7877\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7817 - accuracy: 0.7713\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7792 - accuracy: 0.7719\n",
            "evaluating model anne at stage 11\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 5s 45ms/step - loss: 0.7628 - accuracy: 0.7879\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.7524 - accuracy: 0.7853\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.7660 - accuracy: 0.8106\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7499 - accuracy: 0.7996\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7507 - accuracy: 0.7824\n",
            "evaluating model anne at stage 12\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 5s 33ms/step - loss: 0.7524 - accuracy: 0.7940\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7444 - accuracy: 0.8043\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7451 - accuracy: 0.7819\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7366 - accuracy: 0.7901\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7396 - accuracy: 0.8103\n",
            "evaluating model anne at stage 13\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 5s 41ms/step - loss: 0.7445 - accuracy: 0.7912\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7352 - accuracy: 0.7974\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7376 - accuracy: 0.8120\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7271 - accuracy: 0.7889\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7318 - accuracy: 0.7827\n",
            "evaluating model anne at stage 14\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 5s 35ms/step - loss: 0.7594 - accuracy: 0.7957\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7473 - accuracy: 0.7947\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7571 - accuracy: 0.7767\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7414 - accuracy: 0.7957\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7463 - accuracy: 0.8070\n",
            "evaluating model anne at stage 15\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 29ms/step - loss: 0.6815 - accuracy: 0.8240\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.6730 - accuracy: 0.8120\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6720 - accuracy: 0.8276\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6653 - accuracy: 0.8080\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6641 - accuracy: 0.8098\n",
            "evaluating model anne at stage 16\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 34ms/step - loss: 0.7334 - accuracy: 0.8013\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7277 - accuracy: 0.8025\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7405 - accuracy: 0.8143\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7229 - accuracy: 0.8080\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7304 - accuracy: 0.7941\n",
            "evaluating model anne at stage 17\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 28ms/step - loss: 0.7104 - accuracy: 0.8105\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7041 - accuracy: 0.8181\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7064 - accuracy: 0.8013\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6974 - accuracy: 0.8152\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7004 - accuracy: 0.8219\n",
            "evaluating model anne at stage 18\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 28ms/step - loss: 0.7478 - accuracy: 0.7961\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7418 - accuracy: 0.7978\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7571 - accuracy: 0.8044\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7369 - accuracy: 0.8013\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7487 - accuracy: 0.7803\n",
            "evaluating model anne at stage 19\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 33ms/step - loss: 0.7450 - accuracy: 0.8034\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7369 - accuracy: 0.8061\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7428 - accuracy: 0.7881\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7302 - accuracy: 0.8095\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7338 - accuracy: 0.8119\n",
            "evaluating model anne at stage 20\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "13/13 [==============================] - 7s 32ms/step - loss: 3.6988 - accuracy: 0.0216\n",
            "Epoch 2/5\n",
            "13/13 [==============================] - 0s 30ms/step - loss: 3.3665 - accuracy: 0.5616\n",
            "Epoch 3/5\n",
            "13/13 [==============================] - 0s 30ms/step - loss: 2.6313 - accuracy: 0.8276\n",
            "Epoch 4/5\n",
            "13/13 [==============================] - 0s 30ms/step - loss: 1.7155 - accuracy: 0.8276\n",
            "Epoch 5/5\n",
            "13/13 [==============================] - 0s 30ms/step - loss: 1.1490 - accuracy: 0.8276\n",
            "evaluating model aran at stage 1\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "6/6 [==============================] - 4s 32ms/step - loss: 1.0158 - accuracy: 0.8055\n",
            "Epoch 2/5\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.9313 - accuracy: 0.8055\n",
            "Epoch 3/5\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.8721 - accuracy: 0.8055\n",
            "Epoch 4/5\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.8294 - accuracy: 0.8055\n",
            "Epoch 5/5\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.7994 - accuracy: 0.8055\n",
            "evaluating model aran at stage 2\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 4s 52ms/step - loss: 0.7710 - accuracy: 0.8075\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.7519 - accuracy: 0.8079\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.7372 - accuracy: 0.8081\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.7252 - accuracy: 0.8077\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.7142 - accuracy: 0.8103\n",
            "evaluating model aran at stage 3\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 4s 53ms/step - loss: 0.7651 - accuracy: 0.7996\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.7572 - accuracy: 0.7982\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.7538 - accuracy: 0.7949\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.7448 - accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.7414 - accuracy: 0.8073\n",
            "evaluating model aran at stage 4\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 4s 52ms/step - loss: 0.7305 - accuracy: 0.8038\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.7214 - accuracy: 0.8081\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.7165 - accuracy: 0.8112\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.7089 - accuracy: 0.8006\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.7016 - accuracy: 0.8023\n",
            "evaluating model aran at stage 5\n",
            "Words learned: 0\n",
            "Percentage: 0.0\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-225-a3cb17ef010f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluating model {} at stage {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mwords_learned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-97-26cb510ff142>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, epochs, e_input, d_input, d_target)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     model.fit([e_input, d_input], d_target,\n\u001b[0m\u001b[1;32m      4\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_df = pd.DataFrame(columns=('id', 'stage', 'phon', 'phon_str'))\n",
        "for i in range(len(models)):\n",
        "    already_learned = set()\n",
        "    for j in range(20):\n",
        "        stage = j+1\n",
        "        encoder_input, decoder_input, decoder_target = get_dataset(ids[i], stage)\n",
        "        train_model(models[i], 20, encoder_input, decoder_input, decoder_target)\n",
        "        print('evaluating model {} at stage {}'.format(ids[i], stage))\n",
        "        words_learned = evaluate_model2(inference_models[i][0], inference_models[i][1],words_train)\n",
        "        for word in words_learned:\n",
        "            word_str = '_'.join(word)\n",
        "            if not (word_str in already_learned):\n",
        "                model_df.loc[len(model_df.index)] = [ids[i], stage, word, word_str]\n",
        "                already_learned.add(word_str)\n",
        "        del encoder_input\n",
        "        del decoder_input\n",
        "        del decoder_target\n",
        "        del words_learned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyObp1nrg9h-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}